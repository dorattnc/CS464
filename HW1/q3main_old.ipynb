{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1_alternative.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka0qAmSJBS5Z",
        "outputId": "0e19156b-f93a-453e-d747-69155b4dff6b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "!ls /content/gdrive/My\\ Drive/Dora/Bilkent/CS464/HW1 # Use YOUR OWN DIRECTORY!!\r\n",
        "\r\n",
        "\r\n",
        "import os\r\n",
        "import csv\r\n",
        "import math\r\n",
        "import random\r\n",
        "import operator\r\n",
        "import pdb\r\n",
        "import time\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import scipy as scp\r\n",
        "\r\n",
        "from timeit import default_timer as timer\r\n",
        "from math import log, inf\r\n",
        "\r\n",
        "np.random.seed(123)\r\n",
        "\r\n",
        "tic = time.perf_counter()\r\n",
        "\r\n",
        "countfiles = 0\r\n",
        "countspam = 0\r\n",
        "\r\n",
        "root = '/content/gdrive/My Drive/Dora/Bilkent/CS464/HW1'\r\n",
        "csv_yTrain = os.path.join(root, 'y_train.csv')\r\n",
        "csv_xTrain = os.path.join(root, 'x_train.csv')\r\n",
        "csv_yTest = os.path.join(root, 'y_test.csv')\r\n",
        "csv_xTest = os.path.join(root, 'x_test.csv')\r\n",
        "vocab = os.path.join(root, 'vocabulary.txt')\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#read the csv files ot extract the feature and labels from the test and \r\n",
        "train_feature = pd.read_csv(csv_xTrain, header=None)\r\n",
        "train_label = pd.read_csv(csv_yTrain, header=None)\r\n",
        "test_feature = pd.read_csv(csv_xTest, header=None)\r\n",
        "test_label = pd.read_csv(csv_yTest, header=None)\r\n",
        "\r\n",
        "labels = ['0' , '1']\r\n",
        "vocabcount = 44020 #since this quantity is given, it is directly used, however it could've also been easily calculated.\r\n",
        "\r\n",
        "toc = time.perf_counter()\r\n",
        "print(f\"Total time is {toc - tic:0.4f} seconds\")\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "vocabulary.txt\tx_test.csv  x_train.csv  y_test.csv  y_train.csv\n",
            "Total time is 188.1832 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyomIgxpCane",
        "outputId": "36343dfd-8b4d-4d59-ec57-4fc8bc6c42ff"
      },
      "source": [
        "tic = time.perf_counter()\r\n",
        "\r\n",
        "#generate the train_multinomial concatanated matrix to assign training features to their respective labels.\r\n",
        "train_multinomial = pd.concat((train_label[0].rename('label'), train_feature), axis=1)\r\n",
        "\r\n",
        "#count the number of spam and normal mails in the training dataset\r\n",
        "label_counts = train_label[0].value_counts() \r\n",
        "normal_mails = label_counts[0]\r\n",
        "spam_mails = label_counts[1]\r\n",
        "total_mails = normal_mails + spam_mails\r\n",
        "\r\n",
        "#calculate the probabilities of choosing a normal or a spam email from the dataset.\r\n",
        "prob_normal = normal_mails/total_mails\r\n",
        "prob_spam = spam_mails/total_mails\r\n",
        "\r\n",
        "toc = time.perf_counter()\r\n",
        "print(f\"Total time is {toc - tic:0.4f} seconds\")\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time is 0.1258 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTtcmM8G1OzM"
      },
      "source": [
        ""
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2iwj0Yqf-KL",
        "outputId": "921afc05-4451-492d-f9ea-e13cd962798a"
      },
      "source": [
        "tic = time.perf_counter()\r\n",
        "\r\n",
        "#find the number of occurances of a specific word in the spam and normal datasets, and store it in occurances.\r\n",
        "occurances = train_multinomial.groupby('label').sum()\r\n",
        "\r\n",
        "#extract the total number of each word used in the normal and spam mails seperately.\r\n",
        "normal_total = occurances.sum(axis=1)[0]\r\n",
        "spam_total = occurances.sum(axis=1)[1]\r\n",
        "\r\n",
        "#count the number of times that a particular word has occured. This will be used for the Bernoulli Model.\r\n",
        "countoccurance = train_multinomial.mask(train_multinomial > 1, 1).groupby('label').sum()\r\n",
        "\r\n",
        "toc = time.perf_counter()\r\n",
        "print(f\"Total time is {toc - tic:0.4f} seconds\")\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time is 12.6460 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z8inZqQmHeX"
      },
      "source": [
        "def confusion_results(prediction_matrix):\r\n",
        "\r\n",
        "    #this function is defined to compute the confusion matrix values for the ML models.\r\n",
        "    \r\n",
        "    true_positive = 0\r\n",
        "    true_negative = 0\r\n",
        "    false_negative = 0\r\n",
        "    false_positive = 0 \r\n",
        "\r\n",
        "    for i in range(len(prediction_matrix)):\r\n",
        "        if prediction_matrix[i] == 1 and prediction_matrix[i] == test_label[0][i] :\r\n",
        "            true_positive += 1\r\n",
        "        elif prediction_matrix[i] == 0 and prediction_matrix[i] == test_label[0][i] :\r\n",
        "            true_negative += 1\r\n",
        "        elif prediction_matrix[i] == 1 and prediction_matrix[i] != test_label[0][i] :\r\n",
        "            false_positive += 1\r\n",
        "        elif prediction_matrix[i] == 0 and prediction_matrix[i] != test_label[0][i] :\r\n",
        "            false_negative += 1\r\n",
        "\r\n",
        "    accuracy = (true_positive+true_negative)/(true_negative+true_positive+false_negative+false_positive)*100\r\n",
        "    precision = true_positive / (true_positive + false_positive)*100\r\n",
        "\r\n",
        "    print('Number of True Positives: ', true_positive)\r\n",
        "    print('Number of True Negatives: ', true_negative)\r\n",
        "    print('Number of False Positives: ', false_positive)\r\n",
        "    print('Number of False Negatives: ', false_negative)\r\n",
        "    print('Accuracy is ', accuracy, ' %')\r\n",
        "    print('Precision is ', precision, ' %')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN_rbMnklWwZ"
      },
      "source": [
        "def MLE_predictor(email):\r\n",
        "    \r\n",
        "    #this function is used to calculate the posteriors from the Multinomial MLE model, given its priors.\r\n",
        "    #the posteriror for spam and normal will be calculated and compared to reach to a prediction for a particular email document.\r\n",
        "\r\n",
        "    yi_normaldf = (email * np.log((occurances.iloc[0])/(normal_total))).fillna(0)\r\n",
        "    yi_spamdf = (email * np.log((occurances.iloc[1])/(spam_total))).fillna(0) \r\n",
        "\r\n",
        "    yi_normal = yi_normaldf.values.sum() + math.log(prob_normal)\r\n",
        "    yi_spam = yi_spamdf.values.sum() + math.log(prob_spam)\r\n",
        "\r\n",
        "\r\n",
        "    if yi_normal > yi_spam:\r\n",
        "        prediction = 0\r\n",
        "    elif yi_normal < yi_spam:\r\n",
        "        prediction = 1\r\n",
        "    elif yi_normal == yi_spam:\r\n",
        "        prediction = 0\r\n",
        "\r\n",
        "    return prediction\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK3TCczCu13G"
      },
      "source": [
        "def MAP_predictor(email):\r\n",
        "    \r\n",
        "    #this function is used to calculate the posteriors from the MAP model, given its priors.\r\n",
        "    #the posteriror for spam and normal will be calculated and compared to reach to a prediction for a particular email document.\r\n",
        "\r\n",
        "    yi_normaldf = (email * np.log((occurances.iloc[0]+1)/(normal_total+44020))).fillna(0)\r\n",
        "    yi_spamdf = (email * np.log((occurances.iloc[1]+1)/(spam_total+44020))).fillna(0) \r\n",
        "\r\n",
        "    yi_normal = yi_normaldf.values.sum() + math.log(prob_normal)\r\n",
        "    yi_spam = yi_spamdf.values.sum() + math.log(prob_spam)\r\n",
        "\r\n",
        "\r\n",
        "    if yi_normal > yi_spam:\r\n",
        "        prediction = 0\r\n",
        "    elif yi_normal < yi_spam:\r\n",
        "        prediction = 1\r\n",
        "    elif yi_normal == yi_spam:\r\n",
        "        prediction = 0\r\n",
        "\r\n",
        "    return prediction"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWMcaC27u9Xb"
      },
      "source": [
        "def Bernoulli_predictor(email):\r\n",
        "\r\n",
        "    #this function is used to calculate the posteriors from the Bernoulli model, given its priors.\r\n",
        "    #the posteriror for spam and normal will be calculated and compared to reach to a prediction for a particular email document.\r\n",
        "\r\n",
        "    newmail = email.mask(email > 1, 1)\r\n",
        "    compnewmail = 1-newmail\r\n",
        "\r\n",
        "    yi_normaldf = (newmail * np.log((countoccurance.iloc[0])/normal_mails)).fillna(0) + ((compnewmail)*(np.log(1-(countoccurance.iloc[0])/normal_mails))).fillna(0)\r\n",
        "    yi_spamdf = (newmail * np.log((countoccurance.iloc[1])/(spam_mails))).fillna(0) + ((compnewmail)*(np.log(1-(countoccurance.iloc[1])/spam_mails))).fillna(0)\r\n",
        "\r\n",
        "    yi_normal = yi_normaldf.values.sum() + math.log(prob_normal)\r\n",
        "    yi_spam = yi_spamdf.values.sum() + math.log(prob_spam)\r\n",
        "\r\n",
        "    if yi_normal > yi_spam:\r\n",
        "        prediction = 0\r\n",
        "    elif yi_normal < yi_spam:\r\n",
        "        prediction = 1\r\n",
        "    elif yi_normal == yi_spam:\r\n",
        "        prediction = 0\r\n",
        "\r\n",
        "    return prediction"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkrmMxax81SY",
        "outputId": "a2fdf5b7-052c-4e35-d331-02fc01eaf826"
      },
      "source": [
        "prediction_matrix_MLE = []\r\n",
        "np.warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "tic = time.perf_counter()\r\n",
        "\r\n",
        "#the prediction for every document will be conducted from the test features, using the corresponding model.\r\n",
        "#predictions will be stored in its correspondig matrix, each index referring to the respective document. \r\n",
        "\r\n",
        "for i in range(len(test_label)):\r\n",
        "    prediction_matrix_MLE.append(MLE_predictor(test_feature.iloc[i]))\r\n",
        "  \r\n",
        "confusion_results(prediction_matrix_MLE)\r\n",
        "\r\n",
        "toc = time.perf_counter()\r\n",
        "print(f\"Total time is {toc - tic:0.4f} seconds\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of True Positives:  611\n",
            "Number of True Negatives:  317\n",
            "Number of False Positives:  8\n",
            "Number of False Negatives:  150\n",
            "Accuracy is  85.451197053407  %\n",
            "Precision is  98.70759289176091  %\n",
            "Total time is 16.1942 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKl_FJ7gmMR7",
        "outputId": "58141c55-6e6a-4db2-889f-c51ab7b41022"
      },
      "source": [
        "prediction_matrix_MAP = []\r\n",
        "\r\n",
        "tic = time.perf_counter()\r\n",
        "\r\n",
        "#the prediction for every document will be conducted from the test features, using the corresponding model.\r\n",
        "#predictions will be stored in its correspondig matrix, each index referring to the respective document. \r\n",
        "\r\n",
        "for i in range(len(test_label)):\r\n",
        "    prediction_matrix_MAP.append(MAP_predictor(test_feature.iloc[i]))\r\n",
        "  \r\n",
        "confusion_results(prediction_matrix_MAP)\r\n",
        "\r\n",
        "toc = time.perf_counter()\r\n",
        "print(f\"Total time is {toc - tic:0.4f} seconds\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of True Positives:  751\n",
            "Number of True Negatives:  315\n",
            "Number of False Positives:  10\n",
            "Number of False Negatives:  10\n",
            "Accuracy is  98.15837937384899  %\n",
            "Precision is  98.68593955321944  %\n",
            "Total time is 17.4232 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC66Lm0-ypTr",
        "outputId": "ea474725-8fba-461c-c1a1-35052ca33414"
      },
      "source": [
        "prediction_matrix_Bernoulli = []\r\n",
        "np.warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "tic = time.perf_counter()\r\n",
        "\r\n",
        "#the prediction for every document will be conducted from the test features, using the corresponding model.\r\n",
        "#predictions will be stored in its correspondig matrix, each index referring to the respective document. \r\n",
        "\r\n",
        "for i in range(len(test_label)):\r\n",
        "    prediction_matrix_Bernoulli.append(Bernoulli_predictor(test_feature.iloc[i]))\r\n",
        "  \r\n",
        "confusion_results(prediction_matrix_Bernoulli)\r\n",
        "\r\n",
        "toc = time.perf_counter()\r\n",
        "print(f\"Total time is {toc - tic:0.4f} seconds\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of True Positives:  613\n",
            "Number of True Negatives:  300\n",
            "Number of False Positives:  25\n",
            "Number of False Negatives:  148\n",
            "Accuracy is  84.06998158379373  %\n",
            "Precision is  96.08150470219435  %\n",
            "Total time is 33.8550 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}