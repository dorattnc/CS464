{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs464_spring2021_hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDSS2c_hXISc"
      },
      "source": [
        "<b><h1><center>CS 464</center></h1></b>\n",
        "<b><h1><center>Introduction to Machine Learning</center></h1></b>\n",
        "<b><h1><center>Spring 2021</center></h1></b>\n",
        "<b><h1><center>Homework 3</center></h1></b>\n",
        "<h4><center>Due: <b>10 May</b> (GMT+3)</center></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5qurNR3XkKT"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "<ul>\n",
        "    <li>\n",
        "    This homework contains both written and programming questions about neural networks and SVM. </li>\n",
        "    <li>\n",
        "    You are not required to provide answers for <b>Question 1</b> on this notebook. You may use any programming language you like. In either case, you are required to prepare a report for Question 1, named <b>Q1_report.pdf</b>, which contains your results, plots and discussion for Question 1 only.\n",
        "    </li>\n",
        "    <li>\n",
        "    You should implement <b>Question 2</b> on this notebook. Your plots should also be produced in this notebook. Each programming question has its own cell for your answer. You can implement your code directly in these cells, or you can call required functions which are defined in a different location for the given question.\n",
        "    </li>\n",
        "    <li>\n",
        "    For questions that you need to plot, your plot results have to be included in the cell output. For written questions, you may provide them either as comments in code cells or as seperate text cells. \n",
        "    </li>\n",
        "    <li>\n",
        "    For question 1, you are <b>ALLOWED</b> to use machine learning libraries for training SVM models.\n",
        "    </li>\n",
        "    <li>\n",
        "    For questions 2, you are <b>NOT ALLOWED</b> to use different libraries than given libraries in the code segments of this homework except for libraries included in Python Standard Library (https://docs.python.org/3/library/).\n",
        "    </li>\n",
        "    <li>\n",
        "    You are <b>NOT ALLOWED</b> to use a different deep learning framework than PyTorch.\n",
        "    </li>\n",
        "    <li>\n",
        "    <b>IMPORTANT:</b> If you are asked to discuss your results add a new text cell right after you provide your results. On the other hand, if you are asked to provide a written answer for a question add a text cell under the description of the corresponding question. \n",
        "    </li>\n",
        "    <li>\n",
        "    While submitting the homework file, please package notebook(\".ipynb\") and model (\".pth\") files as a gzipped TAR file or a ZIP file with the name cs464_hw3_section#_Firstname_Lastname. Please do not use any Turkish letters for any of your files including code files and model files. Upload your homework to Moodle.\n",
        "    </li>\n",
        "    <li>\n",
        "    This is an individual assignment for each student. That is, you are <b>NOT ALLOWED</b> to share your work with your classmates.</li>\n",
        "    <li> \n",
        "    If you do not follow the submission routes, deadlines and specifications, it will lead to a significant grade deduction.\n",
        "    </li>\n",
        "    <li> \n",
        "    If you have any questions regarding <b>question 1</b> you may send an email to <b>salman.mohammad@bilkent.edu.tr</b>.\n",
        "    </li>\n",
        "    <li> \n",
        "    If you have any questions regarding <b>question 2</b> you may send an email to <b>doruk.cakmakci@bilkent.edu.tr</b>.\n",
        "    </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d7BOVodYiGe"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPlCx2GsYnHS"
      },
      "source": [
        "This homework is prepared by using Google Colab which already has access to required libraries. However, if you are using your own local Jupyter or any other Python notebook editor, you may use both anaconda or pip to install PyTorch to your own computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM4dpplWZBGS"
      },
      "source": [
        "### Anaconda Installation\n",
        "\n",
        "<ul>\n",
        "    <li>Download anaconda from https://www.anaconda.com/download</li>\n",
        "    <li>Follow the instructions provided in https://conda.io/docs/user-guide/install/index.html#regular-installation</li>\n",
        "</ul>\n",
        "\n",
        "#### Creation of Virtual Environment\n",
        "\n",
        "<ul>\n",
        "    <li>Create python3.7 virtual environment for your hw3 using follow command from the command line<br>\n",
        "        <i>> conda create -n HW3 python=3.7 anaconda</i></li>\n",
        "    <li>Activate your virtual environment<br>\n",
        "        <i>> source activate HW3</i></li>\n",
        "    <li>To install auxiliary libraries, replace the \"package_name\" in the following command and run it in activated \"hw3\" environment <br>\n",
        "        <i>> pip install \"package_name\"<i></li>\n",
        "     <li>When you create your virtual environment with \"anaconda\" metapackage, jupyter notebook should be installed. Try:<br>\n",
        "         <i>> jupyter notebook</i>\n",
        "</ul>\n",
        "\n",
        "\n",
        "#### PyTorch Installation with Anaconda\n",
        "\n",
        "You should install PyTorch to your virtual environment which is created for the hw3. Therefore, you should activate your homework virtual environment before to start PyTorch installation.\n",
        "<li>> source activate HW3</li>\n",
        "\n",
        "After you have activated the virtual environment, then use one of the following commands to install pytorch for CPU for your system. See https://pytorch.org/ for help.\n",
        "<ul>\n",
        "<li>For MacOS:<br>\n",
        "    <i>> conda install pytorch torchvision -c pytorch</i>\n",
        "</li>\n",
        "<li>For Linux:<br>\n",
        "    <i>> conda install pytorch-cpu torchvision-cpu -c pytorch</i>\n",
        "</li>\n",
        "<li>For Windows:<br>\n",
        "    <i>> conda install pytorch-cpu torchvision-cpu -c pytorch</i><br>\n",
        "</li>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVlcWIXEZZGO"
      },
      "source": [
        "###Pip3 Installation\n",
        "<ul>\n",
        "    <li>Download pip3 from https://pip.pypa.io/en/stable/installing/</li>\n",
        "    <li>If you are using Windows, you may need to add Python to your enviroment variables. You may use the following tutorial to install Python and pip.\n",
        "    https://phoenixnap.com/kb/how-to-install-python-3-windows</li>\n",
        "</ul>\n",
        "\n",
        "#### PyTorch Installation with Pip\n",
        "<ul>\n",
        "<li>For MacOS:<br>\n",
        "    <i>> pip3 install torch torchvision</i>\n",
        "</li>\n",
        "<li>For Linux:<br>\n",
        "    <i>> pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html</i>\n",
        "</li>\n",
        "<li>For Windows:<br>\n",
        "    <i>> pip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html</i><br>\n",
        "</li>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0CsUtpmZmBk"
      },
      "source": [
        "# Question 1 [30 pts.]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiQo8t-fqMHc"
      },
      "source": [
        "Please refer to Q1.pdf for the question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnAVhRr4eTPo"
      },
      "source": [
        "# Question 2 [70 pts.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnaXgIskP6iY"
      },
      "source": [
        "Computer vision (CV) is the field of study which deals with how computers can gain high-level understanding from digital images or videos. For this question you will develop neural network models to classify images. You are encouraged to use GPU for model training. Here you will use a subset of Fashion-MNIST dataset for evaluating your networks. \n",
        "\n",
        "Fashion-MNIST dataset is composed of: (i) a training set of 60,000 images; and (ii) a test set of 10,000 images. These images are grayscale and have a size of 28x28. Each image belongs to one of the following categories: T-shirt/Top (Class 0), Trouser (Class 1), Pullover (Class 2), Dress (Class 3), Coat (Class 4), Sandal (Class 5), Shirt (Class 6), Sneaker (Class 7), Bag (Class 8) and Ankle boot (Class 9). For this question you will use half of the images in the official training set for training and validating your models, which we will refer to as the development dataset. Furthermore, you will evaluate your trained models on the test dataset. Both development and test datasets are provided to you as a pickled Python dictionary in _q2_dataset_. Keys of the dictionary are the following:\n",
        "*   *development_x*: 30,000 images for training and validating models.\n",
        "*   *development_y*: Class labels for the images in development set.\n",
        "*   *test_x*: 10,000 images for testing the models.\n",
        "*   *test_y*: Class labels for the images in the test set.\n",
        "*   *label2name*: a list whose elements are class names (e.g. Class 0 corresponds to the first element and contains \"T-shirt\").\n",
        "\n",
        "Libraries that are required in this question is given in the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z37KSYkSXHtz"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pdb\n",
        "import pickle\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "from time import time\n",
        "\n",
        "torch.manual_seed(6)\n",
        "torch.cuda.manual_seed(6)\n",
        "np.random.seed(6)\n",
        "\n",
        "# You could add your own libraries form Python Standard Library in this cell. Any other external libraries are not allowed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkd-WIVwTQsn"
      },
      "source": [
        "### Data Loader [5 pts.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjmkpzLCt-CO"
      },
      "source": [
        "An important part of such a task is to implement your own data loader. In this part, you will implement the <b>FashionMNISTDataset</b> class, which inherits from the Dataset class in PyTorch library. This class partially provided to you below.  You need to complete the code below to create your custom <b>FashionMNISTDataset</b> class which will be able to load your dataset. Implement the functions whose prototypes are given. Follow the TODO notes below. You have to divide the development set into <b>training (80%)</b> and <b>validation (20%)</b> sets.  These non-overlapping splits and the test split as well as the list stored at the \"label2name\" field of the dataset dictionary should be retrieved using the <b>create_dataset</b> function. You should create instances of FashionMNISTDataset for each split.  Since this data loader will be called to get the input for different models, your function should work in a least two modes:\n",
        "1. To be compatible with MLP, you need to flatten the images.\n",
        "<br>\n",
        "2. To be compatible with CNN, you need to resize the image to 1x28x28. Note that, you **should not** flatten the image in this mode.\n",
        "\n",
        "Hint 1: The dataset is not normalized and your results will heavily depend on your input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9fac_LpYdXE"
      },
      "source": [
        "class FashionMNISTDataset(Dataset):\n",
        "    # TODO:\n",
        "    \"\"\"Define constructor for FashionMNISTDataset class\n",
        "    HINT: You can pass processed data samples and their ground truth values as parameters\"\"\"\n",
        "    def __init__(self, **kwargs): # you are free to change parameters\n",
        "      pass\n",
        "\n",
        "    '''This function should return sample count in the dataset'''\n",
        "    def __len__(self):\n",
        "        pass\n",
        "\n",
        "    '''This function should return a sample and its ground truth value from the dataset corresponding to index parameter '''\n",
        "    def __getitem__(self, index):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE3b0p2IWrdo"
      },
      "source": [
        "def create_dataset(path_to_dataset_file, mode):\n",
        "    # TODO: \n",
        "    # Read dataset files using pickle library\n",
        "    # Construct training, validation and test sets and return them\n",
        "    label2name = \n",
        "    train_dataset = \n",
        "    vald_dataset = \n",
        "    test_dataset =\n",
        "    return train_dataset, vald_dataset, test_dataset, label2name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz1yad18Yo7m"
      },
      "source": [
        "### Model Implementation [15 pts.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhv_2w2oZVcL"
      },
      "source": [
        "#### Multi Layer Perceptron (MLP) [5 pts.]\n",
        "Now, implement your three layer neural network (i.e. one input and two hidden layers). MLP class, whose template is given below, will represent your neural network. First and second hidden layers will have 256 and 64 neurons, respectively. You will decide on the number of input and output neurons. Use ReLU as your hidden layer activation function. You need to pick a proper activation function for the output layer and a proper weight initialization scheme for fully-connected layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLbnCwuvYy1N"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    '''Define your neural network'''\n",
        "    def __init__(self, **kwargs): # you can add any additional parameters you want \n",
        "      pass\n",
        "    # TODO:\n",
        "    # You should create your neural network here\n",
        "     \n",
        "    def forward(self, X): # you can add any additional parameters you want\n",
        "      pass\n",
        "    # TODO:\n",
        "    # Forward pass implementation should be here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFVQay-2Z7Ix"
      },
      "source": [
        "#### Convolutional Neural Network (CNN) [10 pts]\n",
        "\n",
        "Now implement your convolutional neural network. CNN class, whose template is given below, will represent your convolutional neural network. Your network will have several convolutional layers followed by a fully-connected classification layer. This model utilizes batch normalization which helps to  stabilize the learning process and dramatically reduces the number of training epochs required to train deep networks. You need to choose appropriate input and output neuron sizes, and  activation functions for the fully-connected layers. The architecture can be summarised as follows:\n",
        "<ul>\n",
        "  <li> 64 filters with size of 2 x 2 with stride 1 and zero padding to both sides, ReLU </li>\n",
        "  <li> 2 x 2 max pool. </li>\n",
        "  <li> 128 filters with size of 2 x 2 with stride 1 and zero padding to both sides, Batch Normalization, ReLU </li>\n",
        "  <li> 2 x 2 max pool. </li>\n",
        "  <li> Fully-connected layer </li>\n",
        "</ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNnoeEy-aGA3"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    '''Define your neural network'''\n",
        "    def __init__(self, **kwargs): # you can add any additional parameters you want \n",
        "      pass\n",
        "    # TODO:\n",
        "    # You should create your neural network here\n",
        "     \n",
        "    def forward(self, X): # you can add any additional parameters you want\n",
        "      pass\n",
        "    # TODO:\n",
        "    # Forward propagation implementation should be here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4HT9fvm_jgX"
      },
      "source": [
        "### Model Training [20 pts.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o63kDDoXtzbV"
      },
      "source": [
        "Train both models for 50 epochs with properly processes inputs (i.e. call create_dataset function in mode \"mlp\" for MLP model and mode \"cnn\" for CNN model). Experiment with several optimizers including Stochastic Gradient Descent(SGD), SGD with momentum and Adam. Tune your learning rate. Save your best models (i.e. MLP and CNN models with highest performance) as \"best_mlp.pth\" and \"best_cnn.pth\", respectively. You may use any performance metric to compare performance of the models. However, you must explain your reasoning behind selected optimizer and model. During training you are expected to plot two properly formatted figures per model:\n",
        "<ol>\n",
        "<li>Training and validation losses vs. epochs</li>\n",
        "<li>Accuracy calculated on training and validation sets vs. epoch. \n",
        "</ol>\n",
        "\n",
        "Hint 1: Training the models on CPU should not take days. You are encouraged to train the models on GPU (Runtime > Change Runtime Type). \n",
        "Hint 2: Select batch size mindfully in order to train the models in a reasonable time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnvgLkM5sfGf"
      },
      "source": [
        "#### Train MLP [8 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Zs63u-CQn9"
      },
      "source": [
        "# HINT: note that your training time should not take many days. You may consider training on GPU.\n",
        "\n",
        "# TODO:\n",
        "# Pick your hyper parameters\n",
        "# max_epoch = 50\n",
        "# train_batch = \n",
        "# test_batch = \n",
        "# learning_rate =\n",
        "\n",
        "#use_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "# Create train dataset loader\n",
        "# Create validation dataset loader\n",
        "# Create test dataset loader\n",
        "# initialize your network\n",
        "model = MLP() \n",
        "\n",
        "criterion = # define loss function\n",
        "optimizer =  # define optimizer\n",
        "    \n",
        "# start training\n",
        "# for each epoch calculate validation performance\n",
        "# save best model according to validation performance\n",
        "    \n",
        "# for epoch in range(max_epoch):\n",
        "#    model=model.train()\n",
        "#    iterate over training batches\n",
        "#    ...\n",
        "\n",
        "#    Validation\n",
        "#    model = model.eval()\n",
        "#    with torch.no_grad():\n",
        "#     iterate over validation batches\n",
        "#    if ???????:\n",
        "#       torch.save(model, best_path)\n",
        "\n",
        "# plot losses vs epoch \n",
        "# ...\n",
        "# plt.show()\n",
        "\n",
        "# plot accuracies vs epoch\n",
        "# ...\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9wwVYbf7bzg"
      },
      "source": [
        "#### Train CNN [12 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFQxDL8AtMwn"
      },
      "source": [
        "# HINT: note that your training time should not take many days. You may consider training on GPU.\n",
        "\n",
        "# TODO:\n",
        "# Pick your hyper parameters\n",
        "# max_epoch = 50\n",
        "# train_batch = \n",
        "# test_batch = \n",
        "# learning_rate =\n",
        "\n",
        "#use_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "# Create train dataset loader\n",
        "# Create validation dataset loader\n",
        "# Create test dataset loader\n",
        "# initialize your network\n",
        "model = CNN() \n",
        "\n",
        "criterion = # define loss function\n",
        "optimizer =  # define optimizer\n",
        "    \n",
        "# start training\n",
        "# for each epoch calculate validation performance\n",
        "# save best model according to validation performance\n",
        "    \n",
        "# for epoch in range(max_epoch):\n",
        "#    model=model.train()\n",
        "#    iterate over training batches\n",
        "#    ...\n",
        "\n",
        "#    Validation\n",
        "#    model = model.eval()\n",
        "#    with torch.no_grad():\n",
        "#     iterate over validation batches\n",
        "#    if ???????:\n",
        "#       torch.save(model, best_path)\n",
        "\n",
        "# plot losses vs epoch \n",
        "# ...\n",
        "# plt.show()\n",
        "\n",
        "# plot accuracies vs epoch\n",
        "# ...\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bisc7q7itfPe"
      },
      "source": [
        "### Model Testing [10 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1ddjfw06pn"
      },
      "source": [
        "Report the following for your best model on your test set which has not been seen by the model yet.\n",
        "1. A heatmap for confusion matrix\n",
        "2. Accuracy\n",
        "3. Accuracy for each class\n",
        "4. Macro Precision\n",
        "5. Macro Recall\n",
        "6. Macro F1 Score\n",
        "\n",
        "You may plot the heatmap for the confusion matrix using <b>plot_cm</b> function provided below. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYv0LlpSQ-Dx"
      },
      "source": [
        "def plot_cm(cm, class_labels):\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=range(len(class_labels)),\n",
        "           yticks=range(len(class_labels)),\n",
        "           xticklabels=class_labels, yticklabels=class_labels,\n",
        "           title=\"Confusion Matrix\",\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxsq8CSW6XLe"
      },
      "source": [
        "#### Test MLP [3 pts].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm1n5TJa6dR3"
      },
      "source": [
        "# TODO: \n",
        "# load trained model\n",
        "# test the model by iterating over test batches\n",
        "# calculate and print performance metrics\n",
        "# plot confusion matrix using class names instead of class labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V356T_rI7jXV"
      },
      "source": [
        "#### Test CNN [7 pts]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0pHFbI-9mQf"
      },
      "source": [
        "# TODO: \n",
        "# load trained model\n",
        "# test the model by iterating over test batches\n",
        "# calculate and print performance metrics\n",
        "# plot confusion matrix using class names instead of class labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR8UKIYm9T4e"
      },
      "source": [
        "### Model Comparison [20 pts]\n",
        "\n",
        "Answer the following questions. Your answers <b>must not exceed 200 words</b> in total. Provide the reasoning for your claims:\n",
        "<ul>\n",
        "<li> Discuss the figures that you have plotted in <b>Model Training</b> section\n",
        "<li> In theory, are both models suitable for processing image data? Discuss. </li>\n",
        "<li> Which model performed better on the test set? Do results support your claim for the previous question? Discuss. </li>\n",
        "<li> Which measure/metric (among the ones you considered for this question) would you prefer to assess a model trained for multi-class classification task?\n",
        "<li> Compare both models in terms of complexity.\n",
        "<li> Comment on the inter-class similarity based on your results.\n",
        "</ul>"
      ]
    }
  ]
}